{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert zfl2019.ipynb --to slides --post serve "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Land Use Classification and Machine Learning\n",
    "## ZFL, Bonn March/April 2019\n",
    "### Mort Canty\n",
    "\n",
    "mort.canty@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline\n",
    "Land cover classification of remote sensing imagery is a task which falls into the general category of __pattern recognition__. Pattern recognition problems, in turn, are usually approached by developing appropriate __machine learning algorithms__. Broadly speaking, machine learning involves tasks for which there is no known direct method to compute a desired output from a set of inputs. The strategy adopted is for the computer to learn from a set of representative examples.\n",
    "\n",
    "In the case of supervised classification, the task can often be seen as one of modeling __probability distributions__.  This is called the __training phase__ of the classification procedure. Then these probabilities are used to classify all of the pixels in the image, a step  referred to as the __generalization phase__.\n",
    "\n",
    "The course will treat three representative models for supervised classification which involve probability estimation: a __parametric model__ (the Bayes maximum likelihood classifier), a __nonparametric model__ (kernel density estimation), and a __semiparametric or mixture model__ (the feed-forward neural network or FFN). In addition statistical methods for accuracy assessment and model comparison will be discussed.\n",
    "\n",
    "The theory will be illustrated with Python programs for classification and evaluation, both for local processing as well as on the __Google Earth Engine__. In the case of neural networks, __deep learning__ techniques with __TensorFlow__ will be introduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Software\n",
    "\n",
    "https://mortcanty.github.io/CRC4Docker/\n",
    "\n",
    "https://docs.docker.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### References\n",
    "\n",
    "https://www.crcpress.com/Image-Analysis-Classification-and-Change-Detection-in-Remote-Sensing-With/Canty/p/book/9781138613225\n",
    "\n",
    "https://www.amazon.de/Hands-Machine-Learning-Scikit-Learn-TensorFlow/dp/1491962291/ref=sr_1_1?ie=UTF8&qid=1550754549&sr=8-1&keywords=geron+hands-on+machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "# these are innocuous but irritating\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "# enable in-line graphics\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### The reference ASTER image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!ls imagery | grep AST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "run scripts/dispms -f imagery/AST_20070501_pca.tif -p [1,2,3] -e 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Training data acquired on 1.5.2007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=\"pngs/fig1.png\",width=600,height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The training regions are in ENVI shapefiles in the imagery directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!ls imagery | grep train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!cat imagery/train.txt | grep 'ROI name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "and these have been uploaded to GEE as a table in the shared Asset\n",
    "\n",
    "    users/mortcanty/supervisedclassification/train\n",
    "    \n",
    "together with the 9-band ASTER PCA image \n",
    "\n",
    "    users/mortcanty/supervisedclassification/AST_20070501_pca\n",
    "\n",
    "Here we sample the training regions to get a feature collection of training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()\n",
    "\n",
    "# first 4 principal components of ASTER image\n",
    "image = ee.Image('users/mortcanty/supervisedclassification/AST_20070501_pca') \\\n",
    "            .select(0,1,2,3)\n",
    "\n",
    "# training data\n",
    "table = ee.FeatureCollection('users/mortcanty/supervisedclassification/train')\n",
    "trainData = image.sampleRegions(table,['CLASS_ID'])\n",
    "\n",
    "print trainData.size().getInfo()  \n",
    "s = set(zip(table.aggregate_array('CLASS_NAME').getInfo(),table.aggregate_array('CLASS_ID').getInfo()))\n",
    "list(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayes Maximum Likelihood Classifier (parametric model)\n",
    "\n",
    "#### Decision rule\n",
    "\n",
    "$$\n",
    "  g \\hbox{ is in class } k\\hbox{ provided } Pr(k\\mid g) \\ge Pr(j\\mid g)\\hbox{  for all } j=1\\dots K\n",
    "$$\n",
    "\n",
    "#### Bayes' Rule\n",
    "\n",
    "$$\n",
    "Pr(k\\mid g) =\\ \\ ? \\quad\\to \\quad Pr(k\\mid g) \\approx Pr(k) \\quad\\to \\quad  Pr(k\\mid g) = {p(g\\mid k)\\over p(g)} Pr(k)\n",
    "$$\n",
    "\n",
    "#### All priors equal\n",
    "\n",
    "$$\n",
    "  g \\hbox{ is in class } k\\hbox{ provided } p(g\\mid k) \\ge p(g\\mid j)\\hbox{  for all } j=1\\dots K\n",
    "$$\n",
    "\n",
    "#### Gaussian model assumption\n",
    "\n",
    "$$\n",
    "p(g\\mid k)={1\\over (2\\pi)^{N/2}\\vert\\Sigma_k\\vert^{1/2}}\\exp\\left(\n",
    "-{1\\over 2} (g-\\mu_k)^\\top \\Sigma_k^{-1} (g-\\mu_k) \\right).\n",
    "$$\n",
    "\n",
    "#### Taking logarithm and ignoring class-independent terms\n",
    "\n",
    "$$\n",
    " g \\hbox{ is in class } k\\hbox{ provided } d_k(g) \\ge d_j(g)\\hbox{ for all } j=1\\dots K.\n",
    "$$\n",
    "\n",
    "#### where \n",
    "\n",
    "$$\n",
    "d_k(g) = -\\log\\vert\\Sigma_k\\vert - (g-\\mu_k)^\\top \\Sigma_k^{-1} (g-\\mu_k).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training data separability\n",
    "\n",
    "\n",
    "#### The Bayes error for a binary classifier:\n",
    "\n",
    "$$\n",
    "\\epsilon = \\int\\min[\\ Pr(1\\mid g),Pr(2\\mid g)\\ ]p(g)dg = \\int\\min[\\ p(g\\mid 1)Pr(1),p(g\\mid 2)Pr(2)\\ ]dg.\n",
    "$$\n",
    "\n",
    "#### If the two probability densities are assumed to be Gaussian, we get \n",
    "\n",
    "$$\n",
    "\\epsilon\\le\\epsilon_B =\\sqrt{Pr(1)Pr(2)}\\int \\sqrt{p(g\\mid 1)p(g\\mid 2)}\\ dg = \\sqrt{Pr(1)Pr(2)}\\ e^{-B},\n",
    "$$\n",
    "\n",
    "#### where the Bhattacharyya distance between is:\n",
    "\n",
    "$$\n",
    "B = {1\\over 8}(\\mu_2-\\mu_1)^\\top \\left[{\\Sigma_1+\\Sigma_2\\over 2}\\right]^{-1} (\\mu_2-\\mu_1)\n",
    "+{1\\over 2}\\log\\left({\\left|\\Sigma_1+\\Sigma_2\\right|/2\\over \\sqrt{|\\Sigma_1||\\Sigma_2|}}\\right).\n",
    "$$\n",
    "\n",
    "#### Larger values of $B$ imply smaller Bayes error. The Jeffries-Matusita separability measure is defined in terms of $B$ as\n",
    "\n",
    "$$\n",
    "J = 2(1-e^{-B})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### A function to calculate the Jeffries-Matusita separability on the GEE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def jmsep(class1,class2,image,table): \n",
    "    ''' Jeffries-Matusita separability '''    \n",
    "#  mean and covariance of class1\n",
    "    table1 = table.filter(ee.Filter.eq('CLASS_ID',str(class1))) \n",
    "    m1 = image.reduceRegion(ee.Reducer.mean(),table1).toArray() \n",
    "    s1 = image.toArray().reduceRegion(ee.Reducer.covariance(),table1).toArray()\n",
    "#  mean and covariance of class2    \n",
    "    table2 = table.filter(ee.Filter.eq('CLASS_ID',str(class2)))\n",
    "    m2 = image.reduceRegion(ee.Reducer.mean(),table2).toArray()\n",
    "    s2 = image.toArray().reduceRegion(ee.Reducer.covariance(),table2,15).toArray()\n",
    "#  difference of means     \n",
    "    m12 = m1.subtract(m2)  \n",
    "    m12 = ee.Array([m12.toList()]) # makes 2D matrix, one row and N cols  \n",
    "#  first term in Bhattacharyya distance\n",
    "    s12i = s1.add(s2).divide(2).matrixInverse()\n",
    "    B1 = m12.matrixMultiply(s12i.matrixMultiply(m12.matrixTranspose())).divide(8)\n",
    "#  second term    \n",
    "    ds1 = s1.matrixDeterminant()\n",
    "    ds2 = s2.matrixDeterminant() \n",
    "    ds12 = s1.add(s2).matrixDeterminant()\n",
    "    B2 = ds12.divide(2).divide(ds1.multiply(ds2).sqrt()).log().divide(2)\n",
    "#  add them together    \n",
    "    B = ee.Number(B1.add(B2).project([0]).toList().get(0))\n",
    "#  J-M separability\n",
    "    return ee.Number(1).subtract(ee.Number(1).divide(B.exp())).multiply(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "print jmsep(3,4,image,table).getInfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Band mean values for the training data, illustrating iteration over an ee.List object\n",
    "def band_mean(current,prev):\n",
    "    current = ee.String(current)\n",
    "    prev = ee.Dictionary(prev)\n",
    "    trainData = ee.FeatureCollection(prev.get('trainData'))\n",
    "    class_id = prev.get('class_id')\n",
    "    means = ee.List(prev.get('means'))\n",
    "    mu = trainData.filter(ee.Filter.eq('CLASS_ID',class_id)).aggregate_mean(current)\n",
    "    return ee.Dictionary({ 'trainData':trainData,'class_id':class_id,'means':means.add(mu) })\n",
    "\n",
    "def class_mean(trainData,class_id,bandNames):\n",
    "    first = ee.Dictionary({'trainData':trainData,'class_id':str(class_id),'means':ee.List([])})\n",
    "    return ee.Dictionary(bandNames.iterate(band_mean,first)).get('means')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "mu = ee.Array(class_mean(trainData,9,image.bandNames()))\n",
    "print mu.getInfo()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Naive Bayes on the GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "jet = 'black,blue,cyan,yellow,red,brown'\n",
    "\n",
    "# training data\n",
    "table = ee.FeatureCollection('users/mortcanty/supervisedclassification/train')\n",
    "trainData = image.sampleRegions(table,['CLASS_ID'])\n",
    "\n",
    "# rename the class ids in the trainData feature collection from strings to integers\n",
    "trainData = trainData.remap(['0','1','2','3','4','5','6','7','8','9'],[0,1,2,3,4,5,6,7,8,9],'CLASS_ID')\n",
    "    \n",
    "# train a naive Bayes classifier    \n",
    "classifier = ee.Classifier.continuousNaiveBayes()\n",
    "trained = classifier.train(trainData,'CLASS_ID',image.bandNames())\n",
    "\n",
    "# classify the image and display    \n",
    "classified = image.classify(trained)\n",
    "url = classified.select('classification').getThumbURL({'min':0,'max':9,'palette':jet})\n",
    "Image(url=url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Gaussian Bayes Maximum Likelihood with the classify.py script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "run scripts/classify -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "run scripts/classify -p [1,2,3,4] -a 1 imagery/AST_20070501_pca.tif imagery/train.shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "run scripts/dispms -f imagery/AST_20070501_pca_class.tif -c \\\n",
    "-r  \"['WATER', 'RAPESEED', 'SUGARBEET', 'SUBURBAN', 'INDUSTRIAL', 'CONIFEROUS', 'GRAIN', 'GRASSLAND', 'HERBIFEROUS', 'OPENCAST']\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gauss Kernel Classifier (non-parametric model)\n",
    "\n",
    "####  For training vectors $g(\\nu)$, $\\nu=1\\dots m$, the contribution to the probability density at the point $g(\\nu)$ from class $k$ is\n",
    "\n",
    "$$\n",
    "p(g(\\nu)\\mid k) = {1\\over m_k}\\sum_{\\{\\nu'\\mid \\ell(\\nu') = k\\}}\n",
    "\\exp\\left(-{\\|g(\\nu)-g(\\nu')\\|^2\\over 2\\sigma^2}\\right)\n",
    "= {1\\over m_k}\\sum_{\\{\\nu'\\mid \\ell(\\nu') = k\\}}(\\mathcal{K})_{\\nu\\nu'},\n",
    "$$\n",
    "\n",
    "#### where $\\mathcal{K}$ is an $m\\times m$ *Gaussian kernel matrix* and $\\ell(\\nu)$ is the class label.\n",
    "\n",
    "#### With the rule, choose class $k$ if\n",
    "\n",
    "$$\n",
    "p(g\\mid k) \\ge p(g\\mid j),\\quad j=1\\dots K,\n",
    "$$\n",
    "\n",
    "#### training involves finding the value of $\\sigma$ which minimizes the classification error on the training data themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#run scripts/classify -p [1,2,3,4] -a 2 -P imagery/AST_20070501_pca.tif imagery/train.shp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "run scripts/dispms -f imagery/AST_20070501_pca_classprobs.tif -p [1,2,9] -e 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feed Forward Neural Network (mixture model)\n",
    "\n",
    "### Motivation (for two classes of two-dimensional observations)\n",
    "\n",
    "#### Discriminant function\n",
    "\n",
    "$$\n",
    "I(g) = d_1(g) - d_2(g)\n",
    "$$\n",
    "\n",
    "$$\n",
    "g\\ \\hbox{  is class }\\cases{1 & if $I(g)\\ge0$\\cr 2 & if $I(g)<0$.}\n",
    "$$\n",
    "\n",
    "#### Simplest discriminant\n",
    "\n",
    "$$\n",
    "I(g) = w_0 + w_1g_1+w_2g_2\n",
    "$$\n",
    "\n",
    "#### Decision boundary $I(g)=0)$\n",
    "\n",
    "$$\n",
    "g_2 = -{w_1\\over w_2}g_1-{w_0\\over w_2},\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Image(filename=\"pngs/fig2.png\",width=600,height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### For N-dimensional observations this becomes an *oriented hyperplane*\n",
    "\n",
    "$$\n",
    "I(g) = w_0+w_1g_1+\\dots+w_Ng_N = w^\\top g+w_0\n",
    "$$\n",
    "\n",
    "#### This can be represented graphically as a *perceptron* or *artificial neuron*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Image(filename=\"pngs/fig3.png\",width=600,height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Some jargon:\n",
    "\n",
    "$g_1\\dots g_N$ __input signals__\n",
    "\n",
    "$w_1\\dots W_N$ __synaptic weights__\n",
    "\n",
    "$w_0$ __bias__\n",
    "\n",
    "$I(g)$ __output signal__, which is modified by a non-linear __activation function__ such as\n",
    "\n",
    "$$\n",
    "f(g) = {1\\over 1 + e^{-I(g)}}\n",
    "$$\n",
    "\n",
    "#### For just two Gaussian classes,  $\\Sigma_1=\\Sigma_2$, it is easy to show (text, Chapter 6) that\n",
    "\n",
    "$$\n",
    "Pr(1\\mid g) = {p(g\\mid 1)Pr(1)\\over p(g\\mid 1)Pr(1)+p(g\\mid 2)pr(2)} = {1\\over 1 + e^{-I(g)}} = f(g)\n",
    "$$\n",
    "\n",
    "We expect that the output signal $f(g)$ of the neuron will not only discriminate\n",
    "between the two classes,  __but also  that it will approximate the posterior\n",
    "class membership probability__ $Pr(1\\mid g)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Image(filename=\"pngs/fig4.png\",width=600,height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__There are $K$ neurons (the circles on the right), each of which calculates its own discriminant__\n",
    "\n",
    "$$\n",
    "n_j(g)=f(I_j(g)),\\  j=1\\dots K.\n",
    "$$\n",
    "\n",
    "$$\n",
    "k = \\arg\\max_j n_j(g).\n",
    "$$\n",
    "\n",
    "__For the $j$th neuron,__\n",
    "\n",
    "$$\n",
    "w_j = (w_{0j},w_{1j}\\dots w_{Nj})^\\top,\n",
    "$$\n",
    "\n",
    "__and, for the whole network,__\n",
    "\n",
    "$$\n",
    "W = (w_1,w_2\\dots w_K) = \\pmatrix{ w_{01} & w_{02} & \\cdots & w_{0K}\\cr\n",
    "                                                   w_{11} & w_{12} & \\cdots & w_{1K}\\cr\n",
    "                                                   \\vdots & \\vdots & \\ddots & \\vdots\\cr\n",
    "                                                   w_{N1} & w_{N2} & \\cdots & w_{NK} },\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Image(filename=\"pngs/fig5.png\",width=600,height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Input__\n",
    "\n",
    "$$\n",
    " g(\\nu) = (1,g_1(\\nu)\\dots g_N(\\nu))^\\top.\n",
    "$$\n",
    "\n",
    "__Hidden layer__\n",
    "$$\n",
    "n(\\nu)=(1,n_1(\\nu)\\dots n_L(\\nu))^\\top\n",
    "$$\n",
    "\n",
    "$$\n",
    "n_j(\\nu) = f(I^h_j(g(\\nu))),\\quad j=1\\dots L.\n",
    "$$\n",
    "\n",
    "$$\n",
    "I^h_j(g(\\nu)) =w^{h\\top}_j g(\\nu),\n",
    "$$\n",
    "\n",
    "$$\n",
    "n(\\nu) = \\pmatrix{ 1 \\cr f(W^{h\\top} g(\\nu))}\n",
    "$$\n",
    "\n",
    "__Output layer__\n",
    "\n",
    "$$\n",
    "m(\\nu) = f(W^{o\\top}n(\\nu))\n",
    "$$\n",
    "\n",
    "__Softmax__\n",
    "\n",
    "$$\n",
    "m_k(\\nu) = {e^{I^o_k(n(\\nu))}\\over  e^{I^o_1(n(\\nu))}+e^{I^o_2(n(\\nu))}+\\dots + e^{I^o_K( n(\\nu))}}\n",
    "$$\n",
    "\n",
    "__where__\n",
    "\n",
    "$$\n",
    "I^o_k(n(\\nu)) = w^{o\\top}_k n(\\nu), \\quad k=1\\dots K\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Bishop (1995):__\n",
    "\n",
    "__Two-layer, feed-forward networks can approximate arbitrarily well any functional continuous mapping from one\n",
    "finite dimensional space to another, provided the number of hidden units is sufficiently large. ...\n",
    "An important corollary of this result is, that in the context of a classification problem, networks\n",
    "with sigmoidal non-linearities and two layers of weights can approximate any decision boundary to\n",
    "arbitrary accuracy. ... More generally, the capability of such networks to approximate general smooth\n",
    "functions allows them to model posterior probabilities of class membership.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cost function (catagorical cross-entropy)\n",
    "\n",
    "__Training set__\n",
    "\n",
    "$$\n",
    "\\mathcal{T}=\\{(g(\\nu),\\ell(\\nu))\\mid \\nu=1\\dots m\\},\n",
    "$$\n",
    "\n",
    "__\"One-hot\" encoding__\n",
    "\n",
    "$$\n",
    "\\ell(\\nu) = (0\\dots 0,1,0\\dots 0)^\\top\n",
    "$$\n",
    "\n",
    "__Training: Maximize the probability of observing the earch training example (definition of conditional proabability)__\n",
    "\n",
    "$$\n",
    "Pr(g(\\nu),\\ell(\\nu)) = Pr(\\ell(\\nu)\\mid g(\\nu))\\Pr(g(\\nu)) = \\prod_{k=1}^K [\\ m_k(g(\\nu))\\ ]^{\\ell_k(\\nu)}\n",
    "$$\n",
    "\n",
    "__for example:__\n",
    "\n",
    "$$\n",
    "Pr((1,0\\dots 0)^\\top \\mid g) = m_1(g)^1 \\cdot m_2(g)^0 \\cdots m_K( g)^0 = m_1(g),\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Take negative logarithm, and drop terms independent of the synaptic weights__\n",
    "\n",
    "$$\n",
    "E(W^h,W^o) = - \\sum_{k=1}^K  \\ell_k(\\nu)\\log [m_k(g(\\nu))] \\to \\min\n",
    "$$\n",
    "\n",
    "__In vector notation__\n",
    "\n",
    "$$\n",
    "E(\\nu) = - \\ell(\\nu)^\\top\\log[m(\\nu)]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Backpropagation algorithm (stochastic)\n",
    "\n",
    "\n",
    "1. Initialize the synaptic weights with random numbers and set\n",
    "$\\nu$ equal to a random integer in the interval $[1,m]$.\n",
    "\n",
    "2. Choose training pair $(g(\\nu),\\ell(\\nu))$ and\n",
    "determine the output response $m(\\nu)$ of the network.\n",
    "\n",
    "3. For $k=1\\dots K$ and $j=0\\dots L$, replace $w^o_{jk}$ with\n",
    "$w^o_{jk}-\\eta{\\partial E(\\nu)\\over\\partial w^o_{jk}}$.\n",
    "\n",
    "4. For $j=1\\dots L$ and $i=0\\dots N$, replace $w^h_{ij}$ with\n",
    "$w^h_{ij}-\\eta{\\partial E(\\nu)\\over\\partial w^h_{ij}}$.\n",
    "\n",
    "5. If $\\sum_\\nu E(\\nu)$ ceases to change significantly, stop,\n",
    "otherwise set $\\nu$ equal to a new random integer in $[1,m]$ and go to step 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This is a __gradient descent__ algorithm. If we evaluate the parial derivatives we get\n",
    "\n",
    "For step 3:\n",
    "\n",
    "$$\n",
    "W^o(\\nu+1) = W^o(\\nu) + \\eta\\ n(\\nu) \\delta^o(\\nu)^\\top\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\delta^o(\\nu) = \\ell(\\nu)- m(\\nu)\n",
    "$$\n",
    "\n",
    "For step 4:\n",
    "\n",
    "$$\n",
    "W^h(\\nu+1) = W^h(\\nu) + \\eta \\ g(\\nu)\\delta^h(\\nu)^\\top\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "\\pmatrix{0\\cr \\delta^h(\\nu)} =\n",
    "n(\\nu)\\cdot(1-n(\\nu))\\cdot\\big( W^{o}\\delta^o(\\nu)\\big) \\quad {\\bf Backpropagation!}\n",
    "$$\n",
    "\n",
    "__Note: In order to calculate the derivatives, the signal must first be fed through the network.__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DNN: mplementation of a FFN in low-level TensorFlow \n",
    "\n",
    "\"Deep learning is a particular kind of machine learning that achieves great power and ﬂexibility by representing the world as a nested hierarchy of concepts, with each concept deﬁned in relation to simpler concepts, and more abstract representations computed in terms of less abstract ones.\"\n",
    "\n",
    "##### TensorFlow is not (yet) available on the GEE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Exporting train/test data from GEE to Google Drive for classification with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import ee\n",
    "ee.Initialize()\n",
    "\n",
    "# first 4 principal components of ASTER image\n",
    "image = ee.Image('users/mortcanty/supervisedclassification/AST_20070501_pca') \\\n",
    "            .select(0,1,2,3)\n",
    "\n",
    "# training data\n",
    "table = ee.FeatureCollection('users/mortcanty/supervisedclassification/train')\n",
    "trainData = image.sampleRegions(table,['CLASS_ID'])\n",
    "\n",
    "# a column of random numbers in [0,1]\n",
    "trainTestData = trainData.randomColumn('rand',seed=12345) \n",
    "    \n",
    "# filter on the random column to split into training and test\n",
    "# feature collections in the ration of 2:1\n",
    "trainData = trainTestData.filter(ee.Filter.lt('rand',0.67))\n",
    "testData = trainTestData.filter(ee.Filter.gte('rand',0.67))\n",
    "\n",
    "print 'train pixels: %i'%trainData.size().getInfo()\n",
    "print 'test pixels:  %i'%testData.size().getInfo()    \n",
    "\n",
    "# Export feature collections as csv files\n",
    "gdexport = ee.batch.Export.table.toDrive(trainData,description='driveexporttask',folder= 'EarthEngineImages',fileNamePrefix='traindata')    \n",
    "gdexport.start() \n",
    "\n",
    "gdexport = ee.batch.Export.table.toDrive(testData,description='driveexporttask',folder= 'EarthEngineImages',fileNamePrefix='testdata')    \n",
    "gdexport.start()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### < Download the CSV files from Google Drive to imagery folder>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!ls imagery | grep csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Read in the CSV file as Pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dftrain = pd.read_csv('imagery/traindata.csv')\n",
    "dftest = pd.read_csv('imagery/testdata.csv')\n",
    "print dftrain.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Convert relevant columns to numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "Gstrn = dftrain.values[:,2:6]\n",
    "lstrn = dftrain.values[:,1]\n",
    "\n",
    "Gstst = dftest.values[:,2:6]\n",
    "lstst = dftest.values[:,1]\n",
    "\n",
    "print Gstrn.shape\n",
    "print lstrn.shape\n",
    "print Gstst.shape\n",
    "print lstst.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Digression: tfintro.ipynb\n",
    "\n",
    "#### Now setup the DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "\n",
    "# tensorflow execution graph\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# placeholders\n",
    "Gs = tf.placeholder(tf.float32,shape=(None,4))\n",
    "ls = tf.placeholder(tf.int64,shape=(None))\n",
    "# hidden layer with rectified linear units (relu) \n",
    "hidden=tf.layers.dense(Gs,10,activation=tf.nn.relu)\n",
    "# output layer\n",
    "logits=tf.layers.dense(hidden,10)\n",
    "# cross entropy cost function\n",
    "xentropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=ls,logits=logits)\n",
    "cost=tf.reduce_mean(xentropy)\n",
    "# training algorithm with 0.01 learning rate\n",
    "optimizer=tf.train.GradientDescentOptimizer(0.01)\n",
    "training_op=optimizer.minimize(cost)\n",
    "# variables initializer \n",
    "init=tf.global_variables_initializer()\n",
    "# accuracy evaluation\n",
    "correct=tf.nn.in_top_k(logits,ls,1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct,tf.float32))\n",
    "# saver\n",
    "saver = tf.train.Saver()\n",
    "# logger\n",
    "cost_summary = tf.summary.scalar('COST',cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "logdir = 'tf_logs/run-'+str(now)\n",
    "file_writer = tf.summary.FileWriter(logdir,tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(5000):\n",
    "        if epoch % 200 ==0:\n",
    "            summary_str = cost_summary.eval(feed_dict={Gs:Gstrn,ls:lstrn})\n",
    "            file_writer.add_summary(summary_str,epoch)\n",
    "#        training_op.eval(feed_dict={Gs:Gstrn,ls:lstrn})\n",
    "        sess.run(training_op,feed_dict={Gs:Gstrn,ls:lstrn})\n",
    "    acc = accuracy.eval(feed_dict={Gs:Gstst,ls:lstst})\n",
    "    save_path = saver.save(sess,'imagery/dnn.ckpt')\n",
    "file_writer.close()\n",
    "print 'Test accuracy: %f'%acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir tf_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Prediction, first read in the entire image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import auxil.readshp as rs\n",
    "from osgeo import gdal\n",
    "from osgeo.gdalconst import GA_ReadOnly\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "infile='imagery/AST_20070501_pca.tif'\n",
    "gdal.AllRegister()\n",
    "inDataset = gdal.Open(infile,GA_ReadOnly)\n",
    "# read entire image\n",
    "cols = inDataset.RasterXSize\n",
    "rows = inDataset.RasterYSize  \n",
    "Gs_all = np.zeros((cols*rows,4))\n",
    "for b in range(4):\n",
    "    band = inDataset.GetRasterBand(b+1)\n",
    "    Gs_all[:,b] = band.ReadAsArray(0,0,cols,rows)\\\n",
    "                          .astype(float).ravel()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Now restore the saved model and set up evaluation of the output layer with the full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'imagery/dnn.ckpt')\n",
    "    Z = logits.eval(feed_dict={Gs:Gs_all})\n",
    "    cls = np.argmax(Z,1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(np.reshape(cls/10.0,(rows,cols)),cmap='jet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Implementation in high-level TensorFlow (keras)\n",
    "__Note:__ Here we read the ENVI shapefiles directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "run scripts/classify -p [1,2,3,4] -a 6 -n -e 1000 -L [10,10,10] imagery/AST_20070501_pca.tif imagery/train.shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Digression: Convolutional Neural Networks (CNN)\n",
    "\n",
    "__FFN/DNN for spectral classification__\n",
    "\n",
    "__CNN for spatial classification (object recognition)__\n",
    "\n",
    "https://medium.com/tensorflow/hello-deep-learning-fashion-mnist-with-keras-50fcff8cd74a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Prepare training/test/validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gray_background(img):\n",
    "    return np.where(img>100,img,100)\n",
    "\n",
    "# Load the fashion-mnist pre-shuffled train data and test data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "#x_train = np.array(map(gray_background,x_train))\n",
    "#x_test = np.array(map(gray_background,x_test))\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# normalize the train/test data\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "plt.imshow(x_test[55],cmap='gray',vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Further break training data into train / validation sets (# put 5000 into validation set and keep remaining 55,000 for train)\n",
    "(x_train, x_valid) = x_train[5000:], x_train[:5000] \n",
    "(y_train, y_valid) = y_train[5000:], y_train[:5000]\n",
    "\n",
    "# Reshape input data from (28, 28) to (28, 28, 1)\n",
    "w, h = 28, 28\n",
    "x_train = x_train.reshape(x_train.shape[0], w, h, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], w, h, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], w, h, 1)\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_valid = tf.keras.utils.to_categorical(y_valid, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# Print training set shape\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)\n",
    "\n",
    "# Print the number of training, validation, and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_valid.shape[0], 'validation set')\n",
    "print(x_test.shape[0], 'test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Create the model graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=\"pngs/fig6.png\",width=600,height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "# Must define the input shape in the first layer of the neural network\n",
    "model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1))) \n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "# Take a look at the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# conv2d: (2 times 2 kernel pixels + 1 bias) times 64 filters\n",
    "print (2*2 + 1)*64\n",
    "\n",
    "# conv2d_1: (2 times 2 kernel pixels times 64 filters + 1 bias) times 32 filters\n",
    "print (2*2*64 + 1)*32\n",
    "\n",
    "# flatten: 7*7*32\n",
    "print 7*7*32\n",
    "\n",
    "#dense\n",
    "print 256*(1568+1)\n",
    "\n",
    "# dense_1\n",
    "print 10*(256+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,TensorBoard\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "logdir = 'tf_cnn/run-'+str(now)\n",
    "checkpointer = ModelCheckpoint(filepath='imagery/model.weights.best.hdf5', verbose = 1, save_best_only=True)\n",
    "tensorboardlog = TensorBoard(logdir)\n",
    "\n",
    "model.fit(x_train,\n",
    "         y_train,\n",
    "         batch_size=64,\n",
    "         epochs=5,\n",
    "         validation_data=(x_valid, y_valid),\n",
    "         callbacks=[checkpointer,tensorboardlog])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir tf_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Load the weights with the best validation accuracy\n",
    "model.load_weights('imagery/model.weights.best.hdf5')\n",
    "\n",
    "# Evaluate the model on test set\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "# Print test accuracy\n",
    "print '\\nTest accuracy:', score[1]\n",
    "\n",
    "# save the model\n",
    "# model.save('imagery/model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Apply the model to find  articles of clothing  lost from a flight over Jülich   ;-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "from osgeo.gdalconst import GA_ReadOnly, GDT_Float32\n",
    "import auxil.auxil1 as auxil\n",
    "\n",
    "# make and save a test image\n",
    "gdal.AllRegister()             \n",
    "inDataset = gdal.Open('imagery/LE7_20010525',GA_ReadOnly)     \n",
    "tstimg = auxil.lin2pcstr(inDataset.GetRasterBand(1).ReadAsArray())\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ii = np.random.randint(100,900)\n",
    "        jj = np.random.randint(100,900)\n",
    "        tstimg[ii:ii+28,jj:jj+28] = np.reshape(255*x_train[np.random.randint(0,5000)],(28,28))\n",
    "\n",
    "driver = inDataset.GetDriver() \n",
    "outDataset = driver.Create('imagery/tstimg',1000,1000,1,GDT_Float32) \n",
    "outBand = outDataset.GetRasterBand(1)\n",
    "outBand.WriteArray(tstimg,0,0) \n",
    "outBand.FlushCache()\n",
    "outDataset = None\n",
    "inDataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# restore model\n",
    "model =tf.keras.models.load_model('imagery/model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# read in the test image\n",
    "infile = 'imagery/tstimg'\n",
    "gdal.AllRegister()             \n",
    "inDataset = gdal.Open(infile,GA_ReadOnly)       \n",
    "imagetst = inDataset.GetRasterBand(1).ReadAsArray()/255.\n",
    "inDataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "run scripts/dispms -f 'imagery/tstimg' -e 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "classprobimg = np.zeros((1000,1000))\n",
    "for i in range(14,1000-14):\n",
    "    if i % 100 == 0:\n",
    "        print i\n",
    "    tiles = np.array([np.reshape(imagetst[i-14:i+14,j-14:j+14],(28,28,1)) for j in range(14,1000-14)])\n",
    "    classprobimg[i,0:1000-28] = map(np.max,model.predict(tiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "outDataset = driver.Create('imagery/signal',1000,1000,3,GDT_Float32) \n",
    "signal = np.where(classprobimg>0.999,classprobimg,0)\n",
    "sigimg = np.zeros((3,1000,1000))\n",
    "sigimg[0,:,:] = signal\n",
    "for i in range(3):\n",
    "    outBand = outDataset.GetRasterBand(i+1)\n",
    "    outBand.WriteArray(sigimg[i,:,:],0,0) \n",
    "    outBand.FlushCache()\n",
    "outDataset = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "run scripts/dispms -f  imagery/tstimg -e 4 -d [600,0,400,400] -F imagery/signal -E 2 -P [1,2,3] -o 0.5 -D [600,0,400,400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digression: Autoencoder Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Image(filename=\"pngs/fig7.png\",width=600,height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from osgeo import gdal\n",
    "from osgeo.gdalconst import GA_ReadOnly,GDT_Float32\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# read entire 9-band image\n",
    "infile='imagery/AST_20070501'\n",
    "gdal.AllRegister()\n",
    "inDataset = gdal.Open(infile,GA_ReadOnly)\n",
    "cols = inDataset.RasterXSize\n",
    "rows = inDataset.RasterYSize  \n",
    "bands = inDataset.RasterCount\n",
    "Gs = np.zeros((cols*rows,bands))\n",
    "for b in range(bands):\n",
    "    band = inDataset.GetRasterBand(b+1)\n",
    "    Gs[:,b] = band.ReadAsArray(0,0,cols,rows)\\\n",
    "                          .astype(float).ravel() \n",
    "\n",
    "# autoencode to three principal components    \n",
    "n_inputs = bands\n",
    "n_hidden = 3\n",
    "n_outputs = n_inputs\n",
    "n_iterations = 1000\n",
    "\n",
    "# tensorflow graph\n",
    "tf.reset_default_graph()    \n",
    "X = tf.placeholder(tf.float32,shape=[None,bands]) \n",
    "hidden = tf.layers.dense(X,n_hidden)\n",
    "outputs = tf.layers.dense(hidden,n_outputs)\n",
    "\n",
    "# mean square loss function\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(outputs-X))\n",
    "optimizer = tf.train.AdamOptimizer(0.01)\n",
    "training_op = optimizer.minimize(reconstruction_loss)\n",
    "init = tf.global_variables_initializer()\n",
    "codings = hidden  # the principal components image\n",
    "recons = outputs  # the reconstructed image\n",
    "# logger\n",
    "cost_summary = tf.summary.scalar('ACCURACY',reconstruction_loss)\n",
    "\n",
    "# run the graph\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "logdir = 'tf_logs/run-'+str(now)\n",
    "file_writer = tf.summary.FileWriter(logdir,tf.get_default_graph())\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(n_iterations):\n",
    "        if iteration % 10 ==0:\n",
    "            summary_str = cost_summary.eval(feed_dict={X:Gs})\n",
    "            file_writer.add_summary(summary_str,iteration)        \n",
    "        training_op.run(feed_dict = {X:Gs})\n",
    "    codings_val = codings.eval(feed_dict = {X:Gs})\n",
    "    recons_val = recons.eval(feed_dict = {X:Gs})\n",
    "\n",
    "# output codings (PCs) to disk\n",
    "driver = gdal.GetDriverByName('GTiff') \n",
    "outDataset = driver.Create('imagery/codings.tif',cols,rows,n_hidden,GDT_Float32)    \n",
    "for k in range(n_hidden):        \n",
    "    outBand = outDataset.GetRasterBand(k+1)\n",
    "    outBand.WriteArray(np.reshape(codings_val[:,k],(cols,rows)))\n",
    "    outBand.FlushCache() \n",
    "\n",
    "# output reconstruction to disk\n",
    "driver = gdal.GetDriverByName('GTiff') \n",
    "outDataset = driver.Create('imagery/recons.tif',cols,rows,bands,GDT_Float32)    \n",
    "for k in range(bands):        \n",
    "    outBand = outDataset.GetRasterBand(k+1)\n",
    "    outBand.WriteArray(np.reshape(recons_val[:,k],(cols,rows)))\n",
    "    outBand.FlushCache() \n",
    "inDataset = None\n",
    "outDataset= None\n",
    "\n",
    "print 'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir tf_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run scripts/dispms -f imagery/recons.tif -p [1,2,3] -e 4 -F imagery/AST_20070501 -P [1,2,3] -E 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run scripts/dispms -f imagery/codings.tif -p [1,2,3] -e 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
